# Introduction #

Flow-based processing performs computations by constructing a network of processing nodes with data flowing between them.  There have been attempts in the past to develop the idea as a fundamental programming paradigm (a book, probably easily findable around the internet, that describe the idea in detail is called "Flow-Based Programming" as I remember). More recently, some research on live systems where computation is immediately effective as the programmer edits the program use the same idea. Programming lower-level logic in a flow-based manner can seem cumbersome and inefficient. But for a coarse-grained type of processing like the NLP information extraction in Disco, it seems much better suited.

The basic idea is that a processing node has a bunch of incoming streams of data and bunch of outgoing streams. It continuously receives data from its input and it writes to one or more of its outputs.  This is essentially what Disco does, but in Disco intermediary data is stored in a global namespace (the AnalysisContext) whereas with a flow-based approach, the data will simply flow along communication channels (or pipes) between nodes. A simple way to view this is that the incoming streams provide a continuous source of parameters for a function to perform a computation and produce a continuous stream of results. The advantages of the flow-based approach are that parallel asynchronous processing and memory management (disposal of intermediary results that are no longer needed) are obtained for free as inherent to the model. Also, processing based on a flow-based model will scale seamlessly on many CPUs and machines. The disadvantage is that the programming logic may seem unnatural at first and it may prove difficult to live without a global variable namespace (we'll remove the ability to store temporary data in the AnalysisContext in the hope that we can do without it). Immediate practical disadvantages: (1) pretty much all of the Danalyzers currently in Disco will have to be modified to fit into a new framework - but those are simple modification for the most part. (2) it's a new territory so a bit risky  - that's a bit problematic because I've never used this type of setup before and I'm not 100% on what will come out of it (3) time spend in programming the actual framework -  it's probably a similar time to program any other infrastructure for parallelizing processing.

# Architecture Outline #


  * A processing network is represented by a DataFlowNetwork class that is initialized with all processing nodes and communication channels between them.  This class might need to do some validation that the network is fully connected etc.
  * A Channel is an entity that has one or more input streams and one or more output streams.  A channel's job is to transmit data from the input streams to the output streams in an orderly fashion. It merges data from multiple input streams in an undefined way (as they arrive), but it preserves the order from a single input stream.  It sends the data merged from all input streams to all output streams in the same order. (i.e. all output ports get the exact same stream of data). Each channel is identified by a unique within the network name that is assigned by the programmer.
  * A ProcessingNode is an entity encapsulating an executable processing component (the Danalyzer). Each ProcessingNode is connected to one or more channels for input through input ports and to one or more channels for output through output ports.  [the network is essentially a directed hypergraph, in the sense of Claude Berge's definition, where channels are the directed edges and processing nodes the vertices. ](Thus.md)
  * The role of the ProcessingNode as a wrapper to the real analyzer is to handle low-level management of input-output ports (i.e. interaction with connecting channels) as well as thread management. A ProcessingNode is a thread-like object, but whether each node has its own thread or whether they all share a common pool is an implementation strategy irrelevant to the application. In a relatively small network like what we'll have initially, a simple implementation where each ProcessingNode is bound to and owns a thread will be sufficient. That is, each node will be implemented as a continuously running thread. This strategy will not work in a large network because threads are OS resources that must not be abused. In a large network, a ProcessingNode will need to tap into a pool of threads which complicates the implementation because there must be a way to save the current execution state when the thread of control is yielded to another processor. Fortunately, these days there are good implementations of continuations in Java (google javaflow or RIFE) so this is doable also when the need arises.
  * A special EOF indicator should be used to signal there's no more data on a given channel.  EOF signaling may simply be implemented by closing a port. When a port is closed, an EOF is send to the node listening to it from that point on. EOF drives behavior of channels and nodes in a specific way as detailed below.
  * Danalyzers remain as before, except their process(AnalysisContext) method should accept the set of input and output ports as parameters. Each port is locally identified by the name of the channel to which it connects.
  * Implementations of Danalyzer.process should follow one simple rule: keep on processing as long as there's something to do and exit as soon as there's nothing more to do. A Danalyzer can close an output port thus sending EOF to all connected nodes downstream or close an input port and refuse to receive more data from it, but still continue processing while interacting with other ports.  A Danalyzer can continue producing output after all its input ports are closed. And it can continue doing things after all its input and output ports are closed - but it should exit at some point because once the ports are closed, they will not be reopened again until the analyzer exits.
  * When a Danalyzer tries to read or write to a port, the operation may block. But the analyzer need never concern itself with that.  The only special situation that a Danalyzer may encounter is that an output port has been closed externally. An output port can be closed by a channel when there are no other nodes willing to receive its data. When that happens, the Danalyzer may decide to continue for whatever reason, or simply exit.
  * When a Danalyzer exits, its ProcessingNode becomes inactive and closes all input/output ports that remain open.  This may affect other processing nodes connected to it by a domino effect. Note that a channel must always close its output ports when all of its input ports are closed.
  * There are no restrictions on the data travelling on channels.  There's no mandate that it be homogenous for example. It's all up to the network designer. Well, if the setup is eventually used in a computation that crosses process/machine boundaries, then data should be serializable of course.

# Computation #


The computation proceeds essentially in batch mode - a network is activated by some initiation step and it is not available for another batch (a document in our case) until it has completed.  This limitation can be eventually overcome, but that'll add extra complexity that we want to avoid for now. Each ProcessingNode has a set InSet of input ports and a set OutSet of output ports, all of which are initially in a closed state. The ProcessingNode is bound to a thread with roughly the following endless loop:

  1. Wait for all input ports to open.
  1. Open all output ports.
  1. Call Danalyzer.process(.....)
  1. Close all input and output ports.
  1. Back to step 1

Thus, ultimately the network is activated by opening a root input port.

Note: The idea of having multiple input and output channel connected to a processing node is a generalization of the more simple and common in Disco case where a node will have only a single input and a single output.

# Channels #

Channels are data pipes connected to ProcessingNodes via input and output ports. A channel buffers a limited number of data items (the number is called the channel capacity). A given datum can be discarded from its buffer only after it was successfully transmitted to all its output ports. When all input ports connected to a channel get closed and its data buffer is empty, the channel must close all its output ports. Conversely, when all output ports in a channel are closed, it must close all its input ports and discards all remaining data in its buffer.

A channel participates in the network activation in a way similar to ProcessingNodes: when an input port is opened, the channel opens all its output ports.

Ports themselves are either in an open or closed state. When they are in closed state:  (1) they throw an exception when an attempt is made to write to them (alternatively, the API can be made to return a success/failure code from the ‘put’ method) and (2) they return EOF when an attempt is made to read from them.